{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asr import ASR\n",
    "import mne\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.io.read_raw_edf??\n",
    "from numpy import genfromtxt\n",
    "\n",
    "data_path = os.getcwd()+'/Raw/'\n",
    "data_file = 'record-[2020.07.02-18.14.02].csv'\n",
    "mat_fname = os.path.join(data_path, data_file)\n",
    "\n",
    "data = genfromtxt(mat_fname, delimiter=',')\n",
    "data = np.nan_to_num(data, copy = False)\n",
    "#record-[2020.07.02-18.14.02].csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417217,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.mean(data[1:,:],axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[1:,:] -= np.mean(data[1:,:], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(data[0,:],data[1:,:].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING DATA\n",
    "#---------------\n",
    "#Get data path and load data\n",
    "\n",
    "ch_names = ['Fz', 'C3', 'Cz', 'C4', 'Pz', 'PO7', 'Oz', 'PO8']\n",
    "sfreq=250\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq,  ch_types='eeg')\n",
    "raw = mne.io.RawArray(data[1:,:], info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot raw data\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(raw.get_data().T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESSING\n",
    "#---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate calibration and recording\n",
    "raw_calib = raw.copy()\n",
    "raw_calib.crop(tmax=60.)\n",
    "raw.crop(tmin=60.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize Artifact Subspace Reconstruction\n",
    "asr = ASR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot calibration data\n",
    "\n",
    "x_c = asr.clean_windows(raw_calib)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(x_c.T);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up signal and plot - reconstruct parts with high amplitude noise such as eyeblinks\n",
    "asr.calibrate(k = 15)\n",
    "out = asr.clean(raw)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(out.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE EXTRACTION\n",
    "#---------------\n",
    "\n",
    "#concatenate data of same trials\n",
    "\n",
    "Meditate = np.empty((8,0))\n",
    "Stress = np.empty((8,0))\n",
    "\n",
    "\n",
    "\n",
    "trial_offsets = range(0,len(raw.times), 80*250)\n",
    "trial_len = 60*250\n",
    "\n",
    "for i, o in enumerate(trial_offsets):\n",
    "    if i<10:\n",
    "        #print(i, o)\n",
    "        Meditate = np.concatenate((Meditate, out[:, o: o+trial_len]), axis = 1)\n",
    "    elif i<20:\n",
    "        #print(i, o)\n",
    "        Stress = np.concatenate((Stress, out[:, o: o+trial_len]), axis = 1)\n",
    "    \n",
    "        \n",
    "print(\"amount of data: Meditate \" + str(Meditate.shape[1]) + \" Pos \" + str(Stress.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(data, sf, win_len=2, win_overlap=0.66):\n",
    "    #win_len and win_overlap in s!\n",
    "\n",
    "    n_samples = data.shape[1]\n",
    "    win_samples = int(win_len*sf)\n",
    "    offsets = np.int_(np.arange(0,  n_samples - win_samples, np.round(win_samples * (1 - win_overlap))))\n",
    "\n",
    "    #append window\n",
    "    windows=[]\n",
    "    for o in offsets:\n",
    "        windows.append(data[:,o:o+win_samples])\n",
    "                       \n",
    "    return np.array(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create trials using sliding window\n",
    "\n",
    "Med_windows = sliding_window(Meditate, 256)\n",
    "Stress_windows = sliding_window(Stress, 256)\n",
    "#Neg_windows = sliding_window(Neg, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create labels\n",
    "\n",
    "labels = np.zeros((2, Med_windows.shape[0]+Stress_windows.shape[0]))\n",
    "labels[0,:Med_windows.shape[0]]=1\n",
    "labels[1,Med_windows.shape[0]:Med_windows.shape[0]+Stress_windows.shape[0]] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate all data\n",
    "\n",
    "data = np.concatenate((Med_windows, Stress_windows), axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export data and labels\n",
    "np.save(\"data_Eric.npy\", data)\n",
    "np.save(\"labels_Eric.npy\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLASSIFICATION\n",
    "#---------------\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#extract alpha\n",
    "\n",
    "alpha = mne.filter.filter_data(data, 256, 5, 12)\n",
    "\n",
    "\n",
    "X, y = shuffle(alpha, labels.T)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "\n",
    "def train_riemann_ts(X_data, labels):\n",
    "    # Riemannian Tangent Space Logistic Regression for EEG\n",
    "    # After spatial filtering, covariances matrices are estimated, then projected in the tangent space and classified with a logistic regression.\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define a unique pipeline to sequentially:\n",
    "    clf = make_pipeline(\n",
    "        Covariances(estimator='lwf'),\n",
    "        TangentSpace(),\n",
    "        LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "    scores = cross_validate(clf, X_data, labels, cv=cv, n_jobs=1, return_estimator=True, return_train_score=False)\n",
    "\n",
    "    print('Mean: {0}, Std: {1}'.format(scores['test_score'].mean(), scores['test_score'].std()))\n",
    "\n",
    "    # best_est = scores['estimator'][scores['test_score'].argmax()]\n",
    "    best_est = clf.fit(X_data, labels)  # refit the estimator on the whole set\n",
    "\n",
    "    return best_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chance = 0.5!!\n",
    "est = train_riemann_ts(X_train, np.argmax(y_train, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_confusion_matrix(preds, labels, names)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = est.predict(X_test)\n",
    "true = np.argmax(y_test, axis=1)\n",
    "n = len(pred)\n",
    "\n",
    "print(\"accuracy on test: \" + str(sum(pred == true)/n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trained_rieman.pkl', 'wb') as f:\n",
    "    pickle.dump(est, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asr.calibrate(k = 0)\n",
    "for i in range(X_train.shape[0]):\n",
    "    print(asr.window_reconstruct(X_train[i], 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('cybathlon': conda)",
   "language": "python",
   "name": "python38364bitcybathloncondac28194db8dca48d6b0afc2c4ba5f8a6a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
